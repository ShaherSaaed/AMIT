{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸš€ Neural Network Challenge: *Adult Census Income Dataset*\n",
        "\n",
        "Welcome to todayâ€™s **NN Adventure** ğŸ‰  \n",
        "Your mission:  \n",
        "Build and train a Neural Network to predict whether a person earns **>50K or â‰¤50K** using the famous **Adult Census Income dataset**.  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“‚ Dataset\n",
        "- **Dataset Link (Kaggle):** ğŸ‘‰ [Adult Census Income Dataset](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset)  \n",
        "- Each row = one personâ€™s information.  \n",
        "- Features: age, education, occupation, marital status, etc.  \n",
        "- Target: **income >50K (1) or â‰¤50K (0)**.  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ¯ Your Tasks\n",
        "\n",
        "### 1. Preprocessing\n",
        "ğŸ› ï¸ Clean up the data before the magic happens:  \n",
        "- Handle missing values.  \n",
        "- Encode categorical features (One-Hot or Label Encoding).  \n",
        "- Scale/normalize numerical features.  \n",
        "- Split into **train/validation/test**.  \n",
        "\n",
        "---\n",
        "\n",
        "### 2. Neural Network Model\n",
        "ğŸ’¡ Build your NN (Sequential API *or* Functional API â€” your choice!):  \n",
        "- Input: all preprocessed features.  \n",
        "- Hidden layers: at least 2 Dense layers.  \n",
        "- Use **Batch Normalization (BN)**.  \n",
        "- Add **Dropout** layers (to fight overfitting).  \n",
        "- Output: 1 neuron with **Sigmoid activation**.  \n",
        "\n",
        "---\n",
        "\n",
        "### 3. Early Stopping\n",
        "- Add an **EarlyStopping callback** (monitor `val_loss`).  \n",
        "- Use `restore_best_weights=True`.  \n",
        "- This way, your NN wonâ€™t keep â€œovertrainingâ€ when itâ€™s tired ğŸ˜´.  \n",
        "\n",
        "---\n",
        "\n",
        "### 4. Optimizer Showdown âš”ï¸\n",
        "Train the SAME model with 5 different optimizers:  \n",
        "1. **SGD + Momentum** ğŸƒ  \n",
        "2. **RMSprop** ğŸŒŠ  \n",
        "3. **Adagrad** ğŸ“š  \n",
        "4. **Adam** ğŸ§™   \n",
        "\n",
        "For each optimizer:  \n",
        "- Plot training curves (loss & accuracy).  \n",
        "- Note training time, final validation accuracy, and test performance.  \n",
        "- Compare them: Whoâ€™s the real MVP? ğŸ†  \n",
        "\n",
        "---\n",
        "\n",
        "### 5. Evaluation\n",
        "ğŸ“Š On the test set:  \n",
        "- Report accuracy and loss for each optimizer.  \n",
        "- Write a short fun note:  \n",
        "  - Which optimizer felt like â€œFlashâ€ âš¡ (fast)?  \n",
        "  - Which was â€œThe Tankâ€ ğŸ›¡ï¸ (stable but slower)?  \n",
        "  - Which was the all-rounder ğŸ¯?  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ Deliverables\n",
        "1. **Notebook/Python script** with:  \n",
        "   - Preprocessing  \n",
        "   - Model (BN + Dropout + EarlyStopping)  \n",
        "   - Training with 4 optimizers  \n",
        "   - Plots (loss & accuracy)  \n",
        "\n",
        "---\n",
        "\n",
        "## â­ Bonus (Optional)\n",
        "- Try different **Dropout rates** (0.2, 0.5).  \n",
        "- Play with **Batch size** and see how it changes the curves.  \n",
        "- Use some emojis in your plotsâ€™ titles just for fun ğŸ˜œ.  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ”‘ Reminder\n",
        "Keep your code clean, clear, and commented. Future You (and your instructor ğŸ˜‰) will thank you.  \n"
      ],
      "metadata": {
        "id": "VRIpmDKoioDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0t5ydHlincK"
      },
      "outputs": [],
      "source": []
    }
  ]
}